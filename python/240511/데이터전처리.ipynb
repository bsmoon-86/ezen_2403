{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 설치 \n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 범주형 데이터 처리 \n",
    "- 일반적인 데이터 모델링은 수학적 연산형 모델링이 대부분\n",
    "- 범주형 데이터가 사용이 불가능\n",
    "- 범수형 데이터를 더미 변수를 이용하여 수학적 데이터로 변환\n",
    "- 더미변수 -> 범주형 데이터들을 각각 컬럼의 이름으로 생성 -> 해당 범주에 속하는가? False(0), True(1)로 표현 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.DataFrame(\n",
    "    load_wine()['data'], \n",
    "    columns = load_wine()['feature_names']\n",
    ")\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine['class'] = load_wine()['target']\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 데이터로 변환\n",
    "wine['class'] = wine['class'].map(\n",
    "    {\n",
    "        0 : 'class_0', \n",
    "        1 : 'class_1', \n",
    "        2 : 'class_2'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 컬럼의 데이터들을 더미변수 생성\n",
    "# pandas 안에 있는 get_dummies() 함수를 이용\n",
    "wine_dummy = pd.get_dummies(\n",
    "    wine, \n",
    "    columns = ['class']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_dummy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터의 분할 \n",
    "- 분석 모델을 학습시키고 성과를 확인하기 위해 기존의 데이터 셋을 나눠주는 작업 \n",
    "- 데이터를 학습 데이터(train), 시험 데이터(test)로 나눠주고 데이터들을 일정 비율로 나눠주는 작업 \n",
    "- 일반적인 비율\n",
    "    - Train : Test -> 7 : 3\n",
    "- sklearn에 내장된 train_test_split() 함수를 이용\n",
    "    - train_test_split(X, Y, test_size = None, random_state = None, shuffle = bool, stratify = None)\n",
    "        - X : 독립 변수 \n",
    "        - Y : 종속 변수\n",
    "        - test_size : 테스트 데이터의 비율 (0부터 1 사이의 값)\n",
    "        - random_state : 임의의 번호를 지정, 같은 숫자를 이용한다면 같은 값들을 출력 \n",
    "        - shuffle : True로 지정하면 추출하기 전에 데이터를 섞는다. \n",
    "        - stratify : None이 아닌 경우에는 지정된 변수를 기준으로 계층화를 하여 해당 변수의 비율이 유지 되도록 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립 변수들의 데이터 (2차원 배열)\n",
    "load_iris()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립 변수들의 컬럼의 이름 (1차원 배열)\n",
    "load_iris()['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 종속 변수의 데이터 (1차원 배열)\n",
    "load_iris()['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.DataFrame(\n",
    "    load_iris()['data'], \n",
    "    columns = load_iris()['feature_names']\n",
    ")\n",
    "iris['class'] = load_iris()['target']\n",
    "iris['class'] = iris['class'].map(\n",
    "    {\n",
    "        0 : 'setosa', \n",
    "        1 : 'versicolour', \n",
    "        2 : 'virginaca'\n",
    "    }\n",
    ")\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할 \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    iris.drop('class', axis=1), \n",
    "    iris['class'], \n",
    "    test_size = 0.3, \n",
    "    random_state = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test의 개수를 확인 \n",
    "print('x_train 개수 : ', X_train.shape, 'x_test 개수 :', X_test.shape)\n",
    "print('y_train 개수 :', Y_train.shape, 'y_test 개수 :', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 종속 변수의 데이터 분할이 랜덤하게 이루져있다. \n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris 데이터프레임에서 class 값을 기준으로 데이터를 7:3으로 나눠준다.\n",
    "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(\n",
    "    iris.drop('class', axis=1), \n",
    "    iris['class'], \n",
    "    test_size = 0.3, \n",
    "    random_state = 100, \n",
    "    stratify = iris['class']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 스케일링 \n",
    "- 알고리즘 분석의 대부분은 컬럼 간의 데이터의 범위가 크게 차이가 나면 성능이 떨어지는 부분이 존재 \n",
    "- 값의 범위가 작은 컬럼에 비해서 값의 범위가 큰 컬럼이 타켓 변수를 예측하는데 큰 영향 \n",
    "- 스케일링은 모든 컬럼의 값의 범위를 같게 만들어주는 작업 \n",
    "- 스케일링 순서\n",
    "    - 주의할 점 : 데이터 스케일링은 train데이터와 test 데이터를 같은 scaler를 사용\n",
    "    1. Scaler 선택 및 로드 \n",
    "    2. Scaler 객체를 생성(Class 생성)\n",
    "    3. train 데이터의 분포를 저장 \n",
    "    4. teain 데이터를 스케일링\n",
    "    5. test 데이터를 스케일링\n",
    "    6. 원래의 스케일로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standard Scaler\n",
    "- 표준화 방식으로 기본 스케일링 방식\n",
    "- 컬럼들의 데이터의 평균을 0, 분산이 1인 정규 분포로 스케일링\n",
    "- 회귀분석보다는 분류분석에서 유용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler 로드 \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler 객체 생성 (Class 생성)\n",
    "StdScaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터의 분포 저장 \n",
    "StdScaler.fit(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train 데이터를 스케일링\n",
    "X_train_sc = StdScaler.transform(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 데이터 스케일링\n",
    "X_test_sc = StdScaler.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(X_train_sc.min(), 2))\n",
    "print(round(X_train_sc.max(), 2))\n",
    "print(round(X_train_sc.mean(), 2))\n",
    "print(round(X_train_sc.std(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(X_test_sc.mean(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max Scaler\n",
    "- 정규화 방식으로 컬럼들을 0과 1사이의 값으로 스케일링 하는 방식\n",
    "- 최소값 : 0, 최대값 : 1\n",
    "- 이상치에 굉장히 민감함으로 이상치를 미리 확인하고 제거 \n",
    "- 분류 분석보다는 회귀 분석에서 주로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sclaer 로드 \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Scaler 객체 생성\n",
    "MmScaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data의 범위를 저장 \n",
    "MmScaler.fit(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data를 스케일링\n",
    "X_train_sc2 = MmScaler.transform(X_train2)\n",
    "# test data를 스케일링\n",
    "X_test_sc2 = MmScaler.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(X_train_sc2.min(), 2))\n",
    "print(round(X_train_sc2.max(), 2))\n",
    "print(round(X_train_sc2.mean(), 2))\n",
    "print(round(X_train_sc2.std(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Abs Scaler\n",
    "- 최대절대값과 0을 기준으로 1과 0이 되도록 모든 값이 -1에서 1까지로 표현\n",
    "- 스케일링 데이터가 모두 양수인 경우에는 MinMaxScaler와 동일 \n",
    "- 이상치에 대해 굉장히 민감함으로 이상치를 제거후 스케일링\n",
    "- 분류 분석보다는 회귀 분석에서 유용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "MaScaler = MaxAbsScaler()\n",
    "MaScaler.fit(X_train2)\n",
    "X_train_sc3 = MaScaler.transform(X_train2)\n",
    "X_test_sc3 = MaScaler.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(X_train_sc3.min(), 2))\n",
    "print(round(X_train_sc3.max(), 2))\n",
    "print(round(X_train_sc3.mean(), 2))\n",
    "print(round(X_train_sc3.std(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Scaler \n",
    "- 중앙값과 사분위 값을 활용하여 스케일링 방식\n",
    "- 중앙값을 0으로 설정하고 IQR을 사용하여 이상치의 영향을 최소화하는 스케일링 방식\n",
    "- quantile_range 매개변수(기본값이 [0.25, 0.75])를 조정하여 더 넓거나 좁은 범위로 이상치를 설정하여 정제가 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "RuScaler = RobustScaler()\n",
    "\n",
    "RuScaler.fit(X_train2)\n",
    "\n",
    "X_train_sc4 = RuScaler.transform(X_train2)\n",
    "X_test_sc4 = RuScaler.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중앙값을 확인 \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(X_train_sc4, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원본 데이터로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링 데이터\n",
    "pd.DataFrame(X_train_sc4).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 데이터로 변환\n",
    "X_origin = RuScaler.inverse_transform(X_train_sc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_origin).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
